{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import gc\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Configs\n",
    "diff_threshold = 35        # Mean grayscale difference threshold.\n",
    "max_inpaint_attempts = 10   # Maximum inpainting tries per ROI (batch size).\n",
    "max_roi_attempts = 3       # Maximum ROI re-selections if needed.\n",
    "\n",
    "# Mapping for target keys and prompts.\n",
    "targets = {\n",
    "    \"sphere\": \"single metallic sphere floating, a perfectly uniform, solid metallic sphere with a smooth, mirror-like reflective surface and no visible textures or patterns\",\n",
    "    \"tictac\": \"a smooth, white, capsule-shaped object with rounded edges and a clean, uniform surface\"\n",
    "}\n",
    "\n",
    "# Class mapping for YOLO annotations: sphere->0, tictac->1.\n",
    "class_mapping = {\"sphere\": 0, \"tictac\": 1}\n",
    "\n",
    "# Input directory with images.\n",
    "input_dir = \"mars_images/1200x874\"\n",
    "image_paths = glob.glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "\n",
    "# Create output directories with the new generic folder structure.\n",
    "parent_dir = os.path.dirname(input_dir)\n",
    "output_parent = os.path.join(parent_dir, \"images\")\n",
    "os.makedirs(output_parent, exist_ok=True)\n",
    "\n",
    "img_dir = os.path.join(output_parent, \"img\")\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "mask_dir = os.path.join(output_parent, \"mask\")\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "annotations_dir = os.path.join(output_parent, \"annotations\")\n",
    "os.makedirs(annotations_dir, exist_ok=True)\n",
    "\n",
    "# Determine the current image counter by scanning the img_dir for files named in the format \"img_XXXXXXX.jpg\"\n",
    "existing_files = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\") and f.startswith(\"img_\")]\n",
    "max_counter = 0\n",
    "pattern = re.compile(r\"img_(\\d{7})\\.jpg\")\n",
    "for filename in existing_files:\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        num = int(match.group(1))\n",
    "        if num > max_counter:\n",
    "            max_counter = num\n",
    "\n",
    "# Start a counter for naming images, continuing from the maximum found.\n",
    "img_counter = max_counter + 1\n",
    "\n",
    "# Keep track of processed images using original image names.\n",
    "processed = set()\n",
    "\n",
    "# Initialize the inpainting pipeline (load once for all images).\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Process each image.\n",
    "while image_paths:\n",
    "    input_image_path = image_paths.pop(0)\n",
    "    base_filename = os.path.basename(input_image_path)\n",
    "    name, ext = os.path.splitext(base_filename)\n",
    "    \n",
    "    # Check if this image has already been processed.\n",
    "    if name in processed:\n",
    "        print(f\"Image {name} already processed. Skipping {input_image_path}.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing image: {input_image_path}\")\n",
    "    original_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "    orig_width, orig_height = original_image.size\n",
    "\n",
    "    roi_found = False\n",
    "    roi_attempt = 0\n",
    "    last_inpainted_zoomed = None\n",
    "\n",
    "    # Try multiple ROI selections if needed.\n",
    "    while not roi_found and roi_attempt < max_roi_attempts:\n",
    "        print(f\"--- Processing ROI Batch {roi_attempt+1} ---\")\n",
    "\n",
    "        # 1. Randomly select a cropped region with a random size.\n",
    "        possible_sizes = range(70, 150, 5)\n",
    "        crop_size = random.choice(possible_sizes)\n",
    "        crop_width = crop_height = crop_size\n",
    "        crop_left = random.randint(0, orig_width - crop_width)\n",
    "        crop_top = random.randint(0, orig_height - crop_height)\n",
    "        crop_right = crop_left + crop_width\n",
    "        crop_bottom = crop_top + crop_height\n",
    "        cropped_region = original_image.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "        \n",
    "        # 2. Resize the cropped region to 512x512 for the inpainting model.\n",
    "        zoomed_size = (512, 512)\n",
    "        zoomed_region = cropped_region.resize(zoomed_size, Image.LANCZOS)\n",
    "\n",
    "        # 3. Generate a mask with a centered white rectangle (120x120) on the zoomed image.\n",
    "        mask = Image.new(\"L\", zoomed_size, 0)\n",
    "        mask_size = 120\n",
    "        mask_center_x, mask_center_y = zoomed_size[0] // 2, zoomed_size[1] // 2\n",
    "        mask_left = mask_center_x - mask_size // 2\n",
    "        mask_top = mask_center_y - mask_size // 2\n",
    "        mask_right = mask_center_x + mask_size // 2\n",
    "        mask_bottom = mask_center_y + mask_size // 2\n",
    "        mask_draw = ImageDraw.Draw(mask)\n",
    "        mask_draw.rectangle((mask_left, mask_top, mask_right, mask_bottom), fill=255)\n",
    "\n",
    "        # 4. Randomly choose a prompt and its associated target key.\n",
    "        target_key, prompt = random.choice(list(targets.items()))\n",
    "\n",
    "        # 5. Attempt inpainting several times using a batch.\n",
    "        prompt_list = [prompt] * max_inpaint_attempts\n",
    "        image_list = [zoomed_region] * max_inpaint_attempts\n",
    "        mask_list = [mask] * max_inpaint_attempts\n",
    "\n",
    "        # Batch call to inpainting pipeline.\n",
    "        inpainted_images = pipe(prompt=prompt_list, image=image_list, mask_image=mask_list).images\n",
    "\n",
    "        # Evaluate each inpainted result.\n",
    "        best_diff = -1\n",
    "        best_image = None\n",
    "        for inpainted_zoomed in inpainted_images:\n",
    "            # Calculate mean difference in the masked region.\n",
    "            arr1 = np.array(zoomed_region.crop((mask_left, mask_top, mask_right, mask_bottom)).convert(\"L\"), dtype=np.float32)\n",
    "            arr2 = np.array(inpainted_zoomed.crop((mask_left, mask_top, mask_right, mask_bottom)).convert(\"L\"), dtype=np.float32)\n",
    "            mean_diff = np.mean(np.abs(arr1 - arr2))\n",
    "            \n",
    "            if mean_diff > best_diff:\n",
    "                best_diff = mean_diff\n",
    "                best_image = inpainted_zoomed\n",
    "\n",
    "        if best_diff > diff_threshold:\n",
    "            roi_found = True\n",
    "            last_inpainted_zoomed = best_image\n",
    "        else:\n",
    "            roi_attempt += 1\n",
    "\n",
    "    if roi_found:\n",
    "        # Crop the inpainted result to the masked region.\n",
    "        cropped_inpainted = last_inpainted_zoomed.crop((mask_left, mask_top, mask_right, mask_bottom))\n",
    "        # Compute scale factor from the 512x512 zoomed region to the original cropped region.\n",
    "        scale_factor = crop_width / zoomed_size[0]\n",
    "        resized_masked = cropped_inpainted.resize(\n",
    "            (int(mask_size * scale_factor), int(mask_size * scale_factor)),\n",
    "            Image.LANCZOS\n",
    "        )\n",
    "\n",
    "        paste_x = (crop_width // 2) - (resized_masked.width // 2)\n",
    "        paste_y = (crop_height // 2) - (resized_masked.height // 2)\n",
    "        composite_crop = cropped_region.copy()\n",
    "        composite_crop.paste(resized_masked, (paste_x, paste_y))\n",
    "\n",
    "        # Paste the composite crop back into the original image.\n",
    "        final_image = original_image.copy()\n",
    "        final_image.paste(composite_crop, (crop_left, crop_top))\n",
    "        \n",
    "        # --- Scale the mask to original image coordinates --- \n",
    "        scaled_mask = mask.resize((crop_width, crop_height), Image.LANCZOS)\n",
    "        mask_on_original = Image.new(\"L\", original_image.size, 0)\n",
    "        mask_on_original.paste(scaled_mask, (crop_left, crop_top))\n",
    "        \n",
    "        # Calculate the ROI coordinates on the final image for annotation.\n",
    "        roi_left_coord = crop_left + int(mask_left * scale_factor)\n",
    "        roi_top_coord = crop_top + int(mask_top * scale_factor)\n",
    "        roi_right_coord = roi_left_coord + resized_masked.width\n",
    "        roi_bottom_coord = roi_top_coord + resized_masked.height\n",
    "\n",
    "        # Compute bounding box in YOLO format: normalized center coordinates, width and height.\n",
    "        bbox_width = roi_right_coord - roi_left_coord\n",
    "        bbox_height = roi_bottom_coord - roi_top_coord\n",
    "        center_x = roi_left_coord + bbox_width / 2\n",
    "        center_y = roi_top_coord + bbox_height / 2\n",
    "\n",
    "        norm_center_x = center_x / orig_width\n",
    "        norm_center_y = center_y / orig_height\n",
    "        norm_width = bbox_width / orig_width\n",
    "        norm_height = bbox_height / orig_height\n",
    "\n",
    "        # Prepare the YOLO annotation line.\n",
    "        class_id = class_mapping[target_key]\n",
    "        annotation_line = f\"{class_id} {norm_center_x:.6f} {norm_center_y:.6f} {norm_width:.6f} {norm_height:.6f}\"\n",
    "\n",
    "        # Determine file names using the generic naming convention.\n",
    "        base_out_name = f\"img_{img_counter:07d}\"\n",
    "        img_out_path = os.path.join(img_dir, base_out_name + \".jpg\")\n",
    "        annotation_path = os.path.join(annotations_dir, base_out_name + \".txt\")\n",
    "        mask_out_path = os.path.join(mask_dir, base_out_name + \"_mask.png\")\n",
    "\n",
    "        # Save the final synthesized image.\n",
    "        final_image.save(img_out_path)\n",
    "        # Save the annotation file.\n",
    "        with open(annotation_path, \"w\") as f:\n",
    "            f.write(annotation_line + \"\\n\")\n",
    "        # Save the ROI mask image.\n",
    "        mask_on_original.save(mask_out_path)\n",
    "\n",
    "        print(f\"Saved image to {img_out_path}, annotation to {annotation_path}, and mask to {mask_out_path}.\")\n",
    "\n",
    "        # Mark the original image as processed and increment the counter.\n",
    "        processed.add(name)\n",
    "        img_counter += 1\n",
    "    else:\n",
    "        print(f\"Failed to generate ROI for image: {input_image_path}\")\n",
    "    \n",
    "    # Clear GPU memory and run garbage collection after processing each image.\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def create_split_dirs(base_output_dir: str, split_name: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"Create <split>/img, <split>/mask and <split>/annotations directories (if missing).\"\"\"\n",
    "    split_dir = os.path.join(base_output_dir, split_name)\n",
    "    img_dir = os.path.join(split_dir, \"img\")\n",
    "    mask_dir = os.path.join(split_dir, \"mask\")\n",
    "    ann_dir = os.path.join(split_dir, \"annotations\")\n",
    "\n",
    "    for d in (img_dir, mask_dir, ann_dir):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    return img_dir, mask_dir, ann_dir\n",
    "\n",
    "\n",
    "def _find_matching_file(directory: str, stem: str) -> str | None:\n",
    "    \"\"\"Return the first file inside *directory* that starts with *stem*; None if not found.\"\"\"\n",
    "    matches = glob.glob(os.path.join(directory, f\"{stem}*\"))\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "\n",
    "def split_dataset(\n",
    "    data_dir: str,\n",
    "    output_dir: str,\n",
    "    train_ratio: float = 0.8,\n",
    "    val_ratio: float = 0.1,\n",
    "    test_ratio: float = 0.1,\n",
    "    seed: int = 42,\n",
    ") -> None:\n",
    "    \"\"\"Copy the dataset located in *data_dir* into *output_dir*/{train,val,test} preserving filenames.\n",
    "\n",
    "    The *data_dir* must contain three folders: ``img``, ``mask`` and ``annotations``.\n",
    "    Each image i.e. ``img_000001.jpg`` is expected to have *some* mask/annotation file\n",
    "    that starts with the same stem (``img_000001``).  Extensions & full filenames are preserved.\n",
    "    \"\"\"\n",
    "\n",
    "    if not abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6:\n",
    "        raise ValueError(\"Ratios must add up to 1.0\")\n",
    "\n",
    "    img_dir = os.path.join(data_dir, \"img\")\n",
    "    mask_dir = os.path.join(data_dir, \"mask\")\n",
    "    ann_dir = os.path.join(data_dir, \"annotations\")\n",
    "\n",
    "    try:\n",
    "        images = [f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"))]\n",
    "    except FileNotFoundError as exc:\n",
    "        raise FileNotFoundError(f\"Directory not found: {img_dir}\") from exc\n",
    "\n",
    "    images.sort()\n",
    "    total_images = len(images)\n",
    "    if total_images == 0:\n",
    "        raise RuntimeError(f\"No images found in {img_dir}\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    train_count = int(total_images * train_ratio)\n",
    "    val_count = int(total_images * val_ratio)\n",
    "    test_count = total_images - train_count - val_count\n",
    "\n",
    "    splits = {\n",
    "        \"train\": images[:train_count],\n",
    "        \"val\": images[train_count : train_count + val_count],\n",
    "        \"test\": images[train_count + val_count :],\n",
    "    }\n",
    "\n",
    "    print(f\"Total images: {total_images} | Train {train_count} | Val {val_count} | Test {test_count}\")\n",
    "\n",
    "    # Create the three directory trees once.\n",
    "    dirs = {\n",
    "        name: create_split_dirs(output_dir, name) for name in (\"train\", \"val\", \"test\")\n",
    "    }\n",
    "\n",
    "    def copy_files(img_list: list[str], split_name: str) -> None:\n",
    "        split_img_dir, split_mask_dir, split_ann_dir = dirs[split_name]\n",
    "\n",
    "        for img_filename in img_list:\n",
    "            base_stem, _ = os.path.splitext(img_filename)\n",
    "\n",
    "            src_img = os.path.join(img_dir, img_filename)\n",
    "            dst_img = os.path.join(split_img_dir, img_filename)\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "\n",
    "            # --- mask ---\n",
    "            src_mask = _find_matching_file(mask_dir, base_stem)\n",
    "            if src_mask:\n",
    "                shutil.copy2(src_mask, os.path.join(split_mask_dir, os.path.basename(src_mask)))\n",
    "            else:\n",
    "                print(f\"[WARN] Mask missing for {base_stem}\")\n",
    "\n",
    "            # --- annotation ---\n",
    "            src_ann = _find_matching_file(ann_dir, base_stem)\n",
    "            if src_ann:\n",
    "                shutil.copy2(src_ann, os.path.join(split_ann_dir, os.path.basename(src_ann)))\n",
    "            else:\n",
    "                print(f\"[WARN] Annotation missing for {base_stem}\")\n",
    "\n",
    "    for split_name, files in splits.items():\n",
    "        copy_files(files, split_name)\n",
    "\n",
    "    print(\"Dataset split completed →\", output_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    data_dir = os.path.join(current_dir, \"mars_images\", \"images\")\n",
    "    output_dir = os.path.join(current_dir, \"split_dataset\")\n",
    "\n",
    "    split_dataset(\n",
    "        data_dir,\n",
    "        output_dir,\n",
    "        train_ratio=0.8,\n",
    "        val_ratio=0.1,\n",
    "        test_ratio=0.1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_in_split(split_dir):\n",
    "    \"\"\"\n",
    "    Renames the files in each folder (img, mask, annotations) of the split directory\n",
    "    to have names with a specific prefix and sequential numbering.\n",
    "    \n",
    "    For training: names like train_00001, train_00002, etc.\n",
    "    For evaluation: names like eval_00001, eval_00002, etc. (using the 'val' folder, renamed to eval)\n",
    "    For testing: names like test_00001, test_00002, etc.\n",
    "    \"\"\"\n",
    "    # Determine prefix based on the split name.\n",
    "    split_name = os.path.basename(split_dir)\n",
    "    if split_name == \"val\":\n",
    "        prefix = \"val\"\n",
    "    else:\n",
    "        prefix = split_name\n",
    "\n",
    "    # Define subdirectories.\n",
    "    img_dir = os.path.join(split_dir, \"img\")\n",
    "    mask_dir = os.path.join(split_dir, \"mask\")\n",
    "    ann_dir = os.path.join(split_dir, \"annotations\")\n",
    "    \n",
    "    # Rename image files.\n",
    "    images = sorted(os.listdir(img_dir))\n",
    "    for i, filename in enumerate(images, start=1):\n",
    "        # Get the extension (assumes .jpg)\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        new_name = f\"{prefix}_{i:05d}{ext}\"\n",
    "        os.rename(os.path.join(img_dir, filename), os.path.join(img_dir, new_name))\n",
    "    \n",
    "    # Rename mask files.\n",
    "    masks = sorted(os.listdir(mask_dir))\n",
    "    for i, filename in enumerate(masks, start=1):\n",
    "        # Assuming mask files have the extension .png\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        new_name = f\"{prefix}_{i:05d}_mask{ext}\"\n",
    "        os.rename(os.path.join(mask_dir, filename), os.path.join(mask_dir, new_name))\n",
    "    \n",
    "    # Rename annotation files.\n",
    "    anns = sorted(os.listdir(ann_dir))\n",
    "    for i, filename in enumerate(anns, start=1):\n",
    "        # Assuming annotation files have the extension .txt\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        new_name = f\"{prefix}_{i:05d}{ext}\"\n",
    "        os.rename(os.path.join(ann_dir, filename), os.path.join(ann_dir, new_name))\n",
    "    \n",
    "    print(f\"Renaming completed for split directory: {split_dir}\")\n",
    "\n",
    "def rename_all_splits(output_dir, splits=(\"train\", \"val\", \"test\")):\n",
    "    \"\"\"\n",
    "    Applies the renaming function to all split directories under output_dir.\n",
    "    \"\"\"\n",
    "    for split in splits:\n",
    "        split_dir = os.path.join(output_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            rename_files_in_split(split_dir)\n",
    "        else:\n",
    "            print(f\"Split directory not found: {split_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the current working directory.\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Output directory for the split dataset relative to the current working directory.\n",
    "    output_dir = os.path.join(current_dir, \"split_dataset\")\n",
    "    \n",
    "    # Rename files in each split folder.\n",
    "    rename_all_splits(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell ▶  Replace craft pixels by the average colour of the *surrounding rim*\n",
    "import random, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "ALPHA = 0.50                       # 1 → full flat colour, 0 → none\n",
    "RING_WIDTH = 15                   # dilation kernel size (pixels)\n",
    "ROOT = Path('split_dataset')      # adjust if needed\n",
    "\n",
    "# ───────── pick random img & mask ─────────────────────────────────────────\n",
    "splits = [s for s in ['train', 'val', 'test'] if (ROOT / s).exists()]\n",
    "assert splits, \"No split_dataset found.\"\n",
    "split = random.choice(splits)\n",
    "\n",
    "img_dir, mask_dir = ROOT / split / 'img', ROOT / split / 'mask'\n",
    "img_path = random.choice([p for p in img_dir.glob('*') \n",
    "                          if p.suffix.lower() in {'.jpg', '.jpeg', '.png'}])\n",
    "mask_path = mask_dir / f'{img_path.stem}_mask.png'\n",
    "if not mask_path.exists():\n",
    "    mask_path = mask_dir / f'{img_path.stem}_mask{img_path.suffix}'\n",
    "assert mask_path.exists(), f\"Mask for {img_path.name} not found.\"\n",
    "\n",
    "print(f\"Using  {split}/{img_path.name}\")\n",
    "\n",
    "# ───────── read data ──────────────────────────────────────────────────────\n",
    "img = cv2.imread(str(img_path))\n",
    "msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# ➟ boolean mask: True = craft/object\n",
    "uap_mask = msk > np.percentile(msk, 50)          # minority as craft\n",
    "if uap_mask.sum() > msk.size * 0.5:              # invert if majority\n",
    "    uap_mask = ~uap_mask\n",
    "print(f\"Craft px: {uap_mask.sum()}  |  Total px: {msk.size}\")\n",
    "\n",
    "# ───────── build a thin \"ring\" around the object ─────────────────────────\n",
    "kernel = np.ones((RING_WIDTH, RING_WIDTH), np.uint8)\n",
    "dilated = cv2.dilate(uap_mask.astype(np.uint8), kernel, iterations=1).astype(bool)\n",
    "ring_mask = dilated & (~uap_mask)\n",
    "if ring_mask.sum() == 0:          # rare, e.g. object touches edges\n",
    "    ring_mask = ~uap_mask         # fallback: whole background\n",
    "print(f\"Ring px: {ring_mask.sum()}\")\n",
    "\n",
    "# ───────── average colour of that ring ───────────────────────────────────\n",
    "avg_bgr_ring = img[ring_mask].mean(axis=0).astype(np.uint8)\n",
    "print(\"Average BGR of ring:\", avg_bgr_ring)\n",
    "\n",
    "# ───────── tint only the craft/object pixels ─────────────────────────────\n",
    "tinted = img.astype(np.float32)\n",
    "for c in range(3):\n",
    "    channel = tinted[:, :, c]\n",
    "    channel[uap_mask] = (1 - ALPHA) * channel[uap_mask] + ALPHA * avg_bgr_ring[c]\n",
    "    tinted[:, :, c] = channel\n",
    "tinted = np.clip(tinted, 0, 255).astype(np.uint8)\n",
    "\n",
    "# ───────── visualise ──────────────────────────────────────────────────────\n",
    "fig, axs = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title(\"Original\");          axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(uap_mask, cmap='gray')\n",
    "axs[1].set_title(\"Mask (white = craft)\"); axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(ring_mask, cmap='hot')\n",
    "axs[2].set_title(f\"Ring (width {RING_WIDTH}px)\"); axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(cv2.cvtColor(tinted, cv2.COLOR_BGR2RGB))\n",
    "axs[3].set_title(\"Craft tinted with ring avg\"); axs[3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tint each masked object with the average colour of the surrounding rim.\n",
    "\n",
    "The folder layout must be:\n",
    "split_dataset/\n",
    "    train/\n",
    "        img/            img_XXXX.jpg / .png …\n",
    "        mask/           img_XXXX_mask.png (or same extension)\n",
    "    val/\n",
    "    test/\n",
    "\n",
    "Original filenames are preserved – the edited image overwrites the source.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ───────── PARAMETERS ────────────────────────────────────────────────────\n",
    "ROOT        = Path(\"split_dataset\")   # parent of train/val/test\n",
    "ALPHA       = 0.50                    # 1 → full flat tint, 0 → no change\n",
    "RING_WIDTH  = 15                      # dilation kernel size (pixels)\n",
    "IMG_EXTS    = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"}\n",
    "\n",
    "# ───────── HELPER FUNCTIONS ──────────────────────────────────────────────\n",
    "def get_mask_path(mask_dir: Path, stem: str) -> Path | None:\n",
    "    \"\"\"Return the mask file whose name starts with <stem>_mask.* .\"\"\"\n",
    "    for p in mask_dir.iterdir():\n",
    "        if p.stem.startswith(stem + \"_mask\"):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def tint_image(img_path: Path, mask_path: Path) -> None:\n",
    "    \"\"\"Apply tint to <img_path> in‑place using <mask_path>.\"\"\"\n",
    "    img = cv2.imread(str(img_path))\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Craft mask: minority class = foreground\n",
    "    uap_mask = msk > np.percentile(msk, 50)\n",
    "    if uap_mask.sum() > msk.size * 0.5:\n",
    "        uap_mask = ~uap_mask\n",
    "\n",
    "    # Build thin ring around the craft\n",
    "    kernel  = np.ones((RING_WIDTH, RING_WIDTH), np.uint8)\n",
    "    dilated = cv2.dilate(uap_mask.astype(np.uint8), kernel, iterations=1).astype(bool)\n",
    "    ring    = dilated & (~uap_mask)\n",
    "    if ring.sum() == 0:                      # fallback when object touches edge\n",
    "        ring = ~uap_mask\n",
    "\n",
    "    avg_bgr = img[ring].mean(axis=0)\n",
    "\n",
    "    # Blend only craft pixels toward that colour\n",
    "    tinted = img.astype(np.float32)\n",
    "    for c in range(3):\n",
    "        ch = tinted[:, :, c]\n",
    "        ch[uap_mask] = (1 - ALPHA) * ch[uap_mask] + ALPHA * avg_bgr[c]\n",
    "        tinted[:, :, c] = ch\n",
    "    tinted = np.clip(tinted, 0, 255).astype(np.uint8)\n",
    "\n",
    "    cv2.imwrite(str(img_path), tinted)       # overwrite\n",
    "\n",
    "# ───────── MAIN LOOP ─────────────────────────────────────────────────────\n",
    "splits = [s for s in [\"train\", \"val\", \"test\"] if (ROOT / s).exists()]\n",
    "if not splits:\n",
    "    raise SystemExit(\"No split_dataset directory found.\")\n",
    "\n",
    "for split in splits:\n",
    "    img_dir  = ROOT / split / \"img\"\n",
    "    mask_dir = ROOT / split / \"mask\"\n",
    "    print(f\"\\n▶ Processing split '{split}'\")\n",
    "\n",
    "    img_files = [p for p in img_dir.iterdir() if p.suffix.lower() in IMG_EXTS]\n",
    "    if not img_files:\n",
    "        print(\"  (no images found)\")\n",
    "        continue\n",
    "\n",
    "    for idx, img_path in enumerate(sorted(img_files), 1):\n",
    "        mask_path = get_mask_path(mask_dir, img_path.stem)\n",
    "        if not mask_path:\n",
    "            print(f\"  [SKIP] mask for {img_path.name} not found\")\n",
    "            continue\n",
    "\n",
    "        tint_image(img_path, mask_path)\n",
    "        if idx % 50 == 0 or idx == len(img_files):\n",
    "            print(f\"  {idx}/{len(img_files)} images done\", end=\"\\r\")\n",
    "\n",
    "print(\"\\nAll splits processed – images overwritten with tinted versions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Renumber dataset files so that indices are consecutive\n",
    "# \n",
    "# **Folder layouts supported**\n",
    "# \n",
    "# | Mode | Structure |\n",
    "# |------|-----------|\n",
    "# | `flat` | `dataset/{img, mask, annotations}/img_0001234.*` |\n",
    "# | `split` | `dataset/{train,val,test}/{img,mask,annotations}/img_0001234.*` |\n",
    "# \n",
    "# The script performs a **dry run first** (nothing is renamed).  \n",
    "# Set `DRY_RUN = False` in the *Configuration* cell and rerun the *Execution* cell\n",
    "# once you are happy with the preview.\n",
    "\n",
    "# %%\n",
    "# ─────────────────────────── 1. Configuration ────────────────────────────\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_ROOT = Path(\"uap_10k_mars_aug_dataset\")   # change to \"split_dataset\" if needed\n",
    "ROOT_MODE    = \"split\"            # \"flat\"  or  \"split\"\n",
    "DRY_RUN      = False              # True = preview only; False = rename\n",
    "PAD_LEN      = 7                 # img_0000001.png\n",
    "IMG_EXTS     = {\".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "print(f\"Root: {DATASET_ROOT.resolve()}\\nMode: {ROOT_MODE}\\nDry‑run: {DRY_RUN}\")\n",
    "\n",
    "# %%\n",
    "# ─────────────────────── 2. Helper + Renumber logic ──────────────────────\n",
    "import re, shutil, sys\n",
    "\n",
    "def _parse_index(stem: str):\n",
    "    \"\"\"Return numeric part of 'img_0000123' or None.\"\"\"\n",
    "    m = re.match(r\"img_(\\d+)$\", stem)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def _find_triplets(img_dir: Path, mask_dir: Path, ann_dir: Path):\n",
    "    \"\"\"Yield (img, mask, ann) triples that all exist.\"\"\"\n",
    "    for img in sorted(img_dir.iterdir()):\n",
    "        if img.suffix.lower() not in IMG_EXTS:\n",
    "            continue\n",
    "        if _parse_index(img.stem) is None:\n",
    "            print(f\"[WARN] Bad image name {img.name}; skipped.\")\n",
    "            continue\n",
    "\n",
    "        mask = mask_dir / f\"{img.stem}_mask{img.suffix}\"\n",
    "        if not mask.exists():                 # fallback to .png\n",
    "            mask = mask_dir / f\"{img.stem}_mask.png\"\n",
    "        ann  = ann_dir  / f\"{img.stem}.txt\"\n",
    "\n",
    "        if mask.exists() and ann.exists():\n",
    "            yield img, mask, ann\n",
    "        else:\n",
    "            print(f\"[WARN] Missing pair for {img.name}\")\n",
    "\n",
    "def renumber_split(split_root: Path):\n",
    "    img_dir, mask_dir, ann_dir = (split_root / \"img\",\n",
    "                                  split_root / \"mask\",\n",
    "                                  split_root / \"annotations\")\n",
    "    if not all(d.exists() for d in (img_dir, mask_dir, ann_dir)):\n",
    "        print(f\"[SKIP] {split_root} lacks required sub‑folders\"); return\n",
    "\n",
    "    triples = list(_find_triplets(img_dir, mask_dir, ann_dir))\n",
    "    if not triples:\n",
    "        print(f\"[INFO] No complete triples in {split_root}\"); return\n",
    "\n",
    "    print(f\"\\n▶ Processing '{split_root.relative_to(DATASET_ROOT)}' \"\n",
    "          f\"({len(triples)} triples)\")\n",
    "    for new_idx, (img, mask, ann) in enumerate(triples, start=1):\n",
    "        new_stem  = f\"img_{new_idx:0{PAD_LEN}d}\"\n",
    "        targets = [\n",
    "            (img,  img.with_name(new_stem + img.suffix)),\n",
    "            (mask, mask.with_name(new_stem + \"_mask\" + mask.suffix)),\n",
    "            (ann,  ann.with_name(new_stem + \".txt\")),\n",
    "        ]\n",
    "        for src, dst in targets:\n",
    "            if src == dst:\n",
    "                continue\n",
    "            action = \"DRY‑RUN\" if DRY_RUN else \"RENAMED\"\n",
    "            print(f\"{action:7}  {src.name} → {dst.name}\")\n",
    "            if not DRY_RUN:\n",
    "                shutil.move(src, dst)\n",
    "\n",
    "# %%\n",
    "# ─────────────────────────── 3. Execution cell ───────────────────────────\n",
    "if ROOT_MODE not in {\"flat\", \"split\"}:\n",
    "    sys.exit(\"ROOT_MODE must be 'flat' or 'split'\")\n",
    "\n",
    "if ROOT_MODE == \"flat\":\n",
    "    renumber_split(DATASET_ROOT)\n",
    "else:                                   # split mode\n",
    "    for split in (\"train\", \"val\", \"test\"):\n",
    "        sp_root = DATASET_ROOT / split\n",
    "        if sp_root.exists():\n",
    "            renumber_split(sp_root)\n",
    "\n",
    "print(\"\\n✅ Pass finished.\")\n",
    "if DRY_RUN:\n",
    "    print(\"Nothing was renamed (dry run). \"\n",
    "          \"Set DRY_RUN = False and rerun to apply changes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
